import numpy as np

# Сигмоида
def sigmoid(x, deriv = False):
    if (deriv == True): #Производная сигмоиды
        return x * (1 - x)
    return 1 / (1 + np.exp(-x))

# набор входных данных
X = np.array([[0, 0, 1],
              [0, 1, 1],
              [1, 0, 1],
              [1, 1, 1]])

# выходные данные
y = np.array([[0, 0, 1, 1]]).T
np.random.seed(1) #Сделаем случайные числа более определёнными

# syn0 – первый слой весов, Synapse 0, объединяет l0 с l1
syn0 = 2 * np.random.random((3, 1)) - 1 # Синапс 0

for iter in range(10000):
    # l0 – первый слой сети, определённый входными данными
    l0 = X
    #l1 – второй слой сети, или скрытый слой
    l1 = sigmoid(np.dot(l0, syn0)) #Функция dot() вычисляет скалярное произведение двух массивов
    l1_error = y - l1 #Насколько ошиблись
    l1_delta = l1_error * sigmoid(l1, True) # перемножим это с наклоном сигмоиды, на основе значений в l1
    syn0 += np.dot(l0.T, l1_delta)   # обновим веса

print("Выходные данные после тренировки:")
print(l1)

